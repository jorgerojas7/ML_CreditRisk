{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0d11422",
   "metadata": {},
   "source": [
    "# ğŸ“Š AnÃ¡lisis Exploratorio de Datos (EDA) - PAKDD 2010 Credit Risk\n",
    "\n",
    "Este notebook contiene el anÃ¡lisis exploratorio del dataset PAKDD 2010 para predicciÃ³n de riesgo crediticio.\n",
    "\n",
    "## ğŸ¯ Objetivos:\n",
    "- Cargar y explorar los datos\n",
    "- Entender la estructura del dataset\n",
    "- Analizar distribuciones y patrones\n",
    "- Identificar problemas de calidad de datos\n",
    "- Preparar insights para feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf710f52",
   "metadata": {},
   "source": [
    "## ğŸ“š Importar LibrerÃ­as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff453bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ConfiguraciÃ³n para mostrar todas las columnas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "print(\"âœ… LibrerÃ­as importadas correctamente\")\n",
    "print(f\"ğŸ“¦ Pandas version: {pd.__version__}\")\n",
    "print(f\"ğŸ“¦ NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70d5192",
   "metadata": {},
   "source": [
    "## ğŸ“ Cargar los Datos\n",
    "\n",
    "Vamos a cargar los datos de PAKDD 2010. Este dataset proviene de una competencia real de data mining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd82cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intentar cargar los datos con diferentes separadores\n",
    "try:\n",
    "    # Primero intentemos con tabulaciones\n",
    "    df_train = pd.read_csv('data/raw/PAKDD2010_Modeling_Data.txt', sep='\\t', low_memory=False)\n",
    "    print(f\"âœ… Datos cargados con separador TAB: {df_train.shape}\")\n",
    "except:\n",
    "    try:\n",
    "        # Si no funciona, intentemos con espacios mÃºltiples\n",
    "        df_train = pd.read_csv('data/raw/PAKDD2010_Modeling_Data.txt', sep='\\s+', low_memory=False)\n",
    "        print(f\"âœ… Datos cargados con separador de espacios: {df_train.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error cargando datos: {e}\")\n",
    "        # Intentemos leer las primeras lÃ­neas para ver el formato\n",
    "        with open('data/raw/PAKDD2010_Modeling_Data.txt', 'r') as f:\n",
    "            lines = f.readlines()[:3]\n",
    "            print(\"Primeras lÃ­neas del archivo:\")\n",
    "            for i, line in enumerate(lines, 1):\n",
    "                print(f\"LÃ­nea {i}: {line[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852c4d72",
   "metadata": {},
   "source": [
    "## ğŸ” ExploraciÃ³n Inicial de los Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54990f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# InformaciÃ³n bÃ¡sica del dataset\n",
    "print(\"ğŸ“Š INFORMACIÃ“N BÃSICA DEL DATASET\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ğŸ“ Dimensiones: {df_train.shape[0]:,} filas x {df_train.shape[1]} columnas\")\n",
    "print(f\"ğŸ’¾ TamaÃ±o en memoria: {df_train.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(f\"ğŸ”¢ Tipos de datos:\")\n",
    "print(df_train.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e756f3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver las primeras filas\n",
    "print(\"ğŸ‘€ PRIMERAS 5 FILAS:\")\n",
    "print(\"=\" * 30)\n",
    "display(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59feeaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver las Ãºltimas filas\n",
    "print(\"ğŸ‘€ ÃšLTIMAS 5 FILAS:\")\n",
    "print(\"=\" * 30)\n",
    "display(df_train.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8e14f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# InformaciÃ³n detallada\n",
    "print(\"ğŸ“‹ INFORMACIÃ“N DETALLADA:\")\n",
    "print(\"=\" * 35)\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d46884b",
   "metadata": {},
   "source": [
    "## ğŸ¯ Identificar Variable Objetivo\n",
    "\n",
    "En datasets de riesgo crediticio, la variable objetivo suele ser:\n",
    "- `target`, `default`, `bad_loan`, etc.\n",
    "- TÃ­picamente la Ãºltima columna\n",
    "- Valores binarios (0/1, Y/N, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07ead8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizar la Ãºltima columna (probable variable objetivo)\n",
    "last_col = df_train.columns[-1]\n",
    "print(f\"ğŸ¯ ANÃLISIS DE LA ÃšLTIMA COLUMNA: '{last_col}'\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Valores Ãºnicos: {df_train[last_col].unique()}\")\n",
    "print(f\"Conteo de valores:\")\n",
    "print(df_train[last_col].value_counts())\n",
    "print(f\"\\nPorcentaje:\")\n",
    "print(df_train[last_col].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156aa22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscar posibles variables objetivo en todas las columnas\n",
    "print(\"ğŸ” BUSCANDO VARIABLES BINARIAS (POSIBLES TARGETS):\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "binary_columns = []\n",
    "for col in df_train.columns:\n",
    "    unique_vals = df_train[col].dropna().unique()\n",
    "    if len(unique_vals) == 2:\n",
    "        binary_columns.append(col)\n",
    "        print(f\"âœ“ {col}: {unique_vals}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Total de columnas binarias encontradas: {len(binary_columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf13d3a3",
   "metadata": {},
   "source": [
    "## ğŸ§® EstadÃ­sticas Descriptivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f776ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EstadÃ­sticas para variables numÃ©ricas\n",
    "numeric_cols = df_train.select_dtypes(include=[np.number]).columns\n",
    "print(f\"ğŸ“Š ESTADÃSTICAS DE VARIABLES NUMÃ‰RICAS ({len(numeric_cols)} columnas):\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "if len(numeric_cols) > 0:\n",
    "    display(df_train[numeric_cols].describe())\n",
    "else:\n",
    "    print(\"âŒ No se encontraron columnas numÃ©ricas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760c9911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EstadÃ­sticas para variables categÃ³ricas\n",
    "categorical_cols = df_train.select_dtypes(include=['object']).columns\n",
    "print(f\"ğŸ“Š ESTADÃSTICAS DE VARIABLES CATEGÃ“RICAS ({len(categorical_cols)} columnas):\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for col in categorical_cols[:10]:  # Solo las primeras 10 para no saturar\n",
    "    unique_count = df_train[col].nunique()\n",
    "    print(f\"\\nğŸ·ï¸  {col}:\")\n",
    "    print(f\"   Valores Ãºnicos: {unique_count}\")\n",
    "    if unique_count <= 10:\n",
    "        print(f\"   Top valores: {df_train[col].value_counts().head().to_dict()}\")\n",
    "    else:\n",
    "        print(f\"   Top 5 valores: {df_train[col].value_counts().head().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dc28db",
   "metadata": {},
   "source": [
    "## ğŸ•³ï¸ AnÃ¡lisis de Valores Faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e85f122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular valores faltantes\n",
    "missing_data = df_train.isnull().sum()\n",
    "missing_percent = (missing_data / len(df_train)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': df_train.columns,\n",
    "    'Missing_Count': missing_data.values,\n",
    "    'Missing_Percentage': missing_percent.values\n",
    "})\n",
    "\n",
    "# Filtrar solo columnas con valores faltantes\n",
    "missing_df = missing_df[missing_df['Missing_Count'] > 0].sort_values('Missing_Percentage', ascending=False)\n",
    "\n",
    "print(f\"ğŸ•³ï¸  ANÃLISIS DE VALORES FALTANTES:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"ğŸ“Š Columnas con valores faltantes: {len(missing_df)}/{len(df_train.columns)}\")\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    print(f\"\\nTop 10 columnas con mÃ¡s valores faltantes:\")\n",
    "    display(missing_df.head(10))\n",
    "else:\n",
    "    print(\"âœ… Â¡No hay valores faltantes en el dataset!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17080831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VisualizaciÃ³n de valores faltantes\n",
    "if len(missing_df) > 0:\n",
    "    fig = px.bar(\n",
    "        missing_df.head(15), \n",
    "        x='Missing_Percentage', \n",
    "        y='Column',\n",
    "        title='ğŸ“Š Top 15 Columnas con Valores Faltantes',\n",
    "        labels={'Missing_Percentage': 'Porcentaje Faltante (%)', 'Column': 'Columna'},\n",
    "        color='Missing_Percentage',\n",
    "        color_continuous_scale='Reds'\n",
    "    )\n",
    "    fig.update_layout(height=600)\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"âœ… GrÃ¡fico no necesario - No hay valores faltantes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756f08d0",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ Visualizaciones Exploratorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0877d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DistribuciÃ³n de la variable objetivo (si la identificamos)\n",
    "if len(binary_columns) > 0:\n",
    "    target_col = binary_columns[-1]  # Asumimos que la Ãºltima binaria es el target\n",
    "    \n",
    "    fig = px.pie(\n",
    "        values=df_train[target_col].value_counts().values,\n",
    "        names=df_train[target_col].value_counts().index,\n",
    "        title=f'ğŸ“Š DistribuciÃ³n de la Variable Objetivo: {target_col}'\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "    print(f\"\\nğŸ¯ BALANCE DE CLASES en '{target_col}':\")\n",
    "    print(\"=\" * 40)\n",
    "    class_counts = df_train[target_col].value_counts()\n",
    "    for class_val, count in class_counts.items():\n",
    "        percentage = (count / len(df_train)) * 100\n",
    "        print(f\"   {class_val}: {count:,} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Calcular ratio de desbalance\n",
    "    minority_class = class_counts.min()\n",
    "    majority_class = class_counts.max()\n",
    "    imbalance_ratio = majority_class / minority_class\n",
    "    print(f\"\\nâš–ï¸  Ratio de desbalance: {imbalance_ratio:.2f}:1\")\n",
    "    \n",
    "    if imbalance_ratio > 10:\n",
    "        print(\"âš ï¸  DATASET MUY DESBALANCEADO - Considerar tÃ©cnicas de balanceo\")\n",
    "    elif imbalance_ratio > 3:\n",
    "        print(\"âš ï¸  Dataset moderadamente desbalanceado\")\n",
    "    else:\n",
    "        print(\"âœ… Dataset relativamente balanceado\")\n",
    "else:\n",
    "    print(\"âŒ No se pudo identificar una variable objetivo clara\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe9559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuciones de variables numÃ©ricas\n",
    "if len(numeric_cols) > 0:\n",
    "    # Crear subplots para las primeras 6 variables numÃ©ricas\n",
    "    cols_to_plot = numeric_cols[:6]\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=3,\n",
    "        subplot_titles=[f'DistribuciÃ³n de {col}' for col in cols_to_plot]\n",
    "    )\n",
    "    \n",
    "    for i, col in enumerate(cols_to_plot):\n",
    "        row = i // 3 + 1\n",
    "        col_pos = i % 3 + 1\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Histogram(x=df_train[col].dropna(), name=col, showlegend=False),\n",
    "            row=row, col=col_pos\n",
    "        )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='ğŸ“Š Distribuciones de Variables NumÃ©ricas',\n",
    "        height=800\n",
    "    )\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"âŒ No hay variables numÃ©ricas para graficar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519965b3",
   "metadata": {},
   "source": [
    "## ğŸ” AnÃ¡lisis de Calidad de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45243921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AnÃ¡lisis de duplicados\n",
    "duplicates = df_train.duplicated().sum()\n",
    "duplicate_percentage = (duplicates / len(df_train)) * 100\n",
    "\n",
    "print(f\"ğŸ” ANÃLISIS DE CALIDAD DE DATOS:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"ğŸ“Š Filas duplicadas: {duplicates:,} ({duplicate_percentage:.2f}%)\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    print(\"âš ï¸  Hay filas duplicadas que podrÃ­an necesitar atenciÃ³n\")\n",
    "else:\n",
    "    print(\"âœ… No hay filas duplicadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626b4198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AnÃ¡lisis de cardinalidad (valores Ãºnicos por columna)\n",
    "cardinality_data = []\n",
    "for col in df_train.columns:\n",
    "    unique_count = df_train[col].nunique()\n",
    "    unique_percentage = (unique_count / len(df_train)) * 100\n",
    "    cardinality_data.append({\n",
    "        'Column': col,\n",
    "        'Unique_Count': unique_count,\n",
    "        'Unique_Percentage': unique_percentage,\n",
    "        'Data_Type': str(df_train[col].dtype)\n",
    "    })\n",
    "\n",
    "cardinality_df = pd.DataFrame(cardinality_data)\n",
    "cardinality_df = cardinality_df.sort_values('Unique_Percentage', ascending=False)\n",
    "\n",
    "print(f\"\\nğŸ² ANÃLISIS DE CARDINALIDAD:\")\n",
    "print(\"=\" * 35)\n",
    "print(\"Top 10 columnas con mÃ¡s valores Ãºnicos:\")\n",
    "display(cardinality_df.head(10))\n",
    "\n",
    "# Identificar columnas con alta cardinalidad (posibles IDs)\n",
    "high_cardinality = cardinality_df[cardinality_df['Unique_Percentage'] > 95]\n",
    "if len(high_cardinality) > 0:\n",
    "    print(f\"\\nğŸ†” Posibles columnas ID (alta cardinalidad >95%):\")\n",
    "    for col in high_cardinality['Column']:\n",
    "        print(f\"   â€¢ {col}\")\n",
    "    print(\"ğŸ’¡ Estas columnas probablemente deberÃ­an excluirse del modelado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652c29cf",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Resumen del AnÃ¡lisis Exploratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8bde0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“‹ RESUMEN EJECUTIVO DEL EDA\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ğŸ“ Dimensiones del dataset: {df_train.shape[0]:,} filas Ã— {df_train.shape[1]} columnas\")\n",
    "print(f\"ğŸ’¾ TamaÃ±o en memoria: {df_train.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(f\"ğŸ”¢ Variables numÃ©ricas: {len(numeric_cols)}\")\n",
    "print(f\"ğŸ·ï¸  Variables categÃ³ricas: {len(categorical_cols)}\")\n",
    "print(f\"ğŸ¯ Variables binarias (posibles targets): {len(binary_columns)}\")\n",
    "print(f\"ğŸ•³ï¸  Columnas con valores faltantes: {len(missing_df) if len(missing_df) > 0 else 0}\")\n",
    "print(f\"ğŸ”„ Filas duplicadas: {duplicates:,}\")\n",
    "\n",
    "if len(binary_columns) > 0:\n",
    "    target_col = binary_columns[-1]\n",
    "    class_counts = df_train[target_col].value_counts()\n",
    "    imbalance_ratio = class_counts.max() / class_counts.min()\n",
    "    print(f\"âš–ï¸  Ratio de desbalance: {imbalance_ratio:.2f}:1\")\n",
    "\n",
    "print(\"\\nğŸ¯ PRÃ“XIMOS PASOS RECOMENDADOS:\")\n",
    "print(\"=\" * 40)\n",
    "print(\"1. ğŸ§¹ Limpieza de datos y manejo de valores faltantes\")\n",
    "print(\"2. ğŸ”§ Feature engineering y transformaciones\")\n",
    "print(\"3. ğŸ“Š AnÃ¡lisis de correlaciones\")\n",
    "print(\"4. ğŸ¤– PreparaciÃ³n para modelado\")\n",
    "print(\"5. âš–ï¸  Aplicar tÃ©cnicas de balanceo si es necesario\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
